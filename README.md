# ğŸ‡§ğŸ‡© Bangla Isolated Word Recognition using MFCC + DTW (MATLAB)

This project implements a **simple and effective speech recognition system** for **isolated Bangla words** using:

- **MFCC** (Mel-Frequency Cepstral Coefficients) for acoustic feature extraction
- **DTW** (Dynamic Time Warping) for robust template matching across variable-length utterances

---

## ğŸ¯ Supported Bangla Words

The system currently supports recognition of the following 5 isolated Bangla words:

- **"à¦†à¦¸à§à¦¨"** (ashun)
- **"à¦¹à§à¦¯à¦¾à¦"** (ha / yes)
- **"à¦¨à¦¾"** (na / no)
- **"à¦¬à¦¿à¦¦à¦¾à¦¯à¦¼"** (biday / goodbye)
- **"à¦¬à¦¨à§à¦§"** (bonfho / stop)

---

## ğŸ§  Conceptual and Mathematical Overview

---

### ğŸ”Š 1. MFCC â€” Mel-Frequency Cepstral Coefficients

MFCCs are a compact representation of the short-term power spectrum of a sound, based on human auditory perception. They capture the **timbre** of speech and are widely used in speech recognition systems.

#### ğŸ“‹ Steps in MFCC Computation:

Given a time-domain signal \( x(t) \), the MFCC extraction process includes the following:

1. **Pre-emphasis**  
   Emphasize higher frequencies:
   \[
   x_{\text{pre}}[n] = x[n] - \alpha \cdot x[n - 1] \quad (\alpha \approx 0.95)
   \]

2. **Framing & Windowing**  
   Divide the signal into short frames (e.g., 20â€“30 ms) with overlap. Apply a Hamming window \( w[n] \) to each frame:
   \[
   x_w[n] = x[n] \cdot w[n] = x[n] \cdot \left(0.54 - 0.46 \cos\left(\frac{2\pi n}{N-1}\right)\right)
   \]

3. **FFT & Power Spectrum**  
   Compute the FFT of each windowed frame:
   \[
   X[k] = \sum_{n=0}^{N-1} x_w[n] e^{-j2\pi kn/N}
   \]
   Then compute the power spectrum:
   \[
   P[k] = \frac{1}{N} |X[k]|^2
   \]

4. **Mel Filterbank**  
   Apply a set of \( M \) triangular filters spaced on the Mel scale:
   \[
   \text{Mel}(f) = 2595 \cdot \log_{10} \left(1 + \frac{f}{700}\right)
   \]

5. **Logarithmic Compression**  
   For each filterbank output:
   \[
   E_m = \log\left(\sum_{k=1}^{N} P[k] \cdot H_m[k]\right)
   \]
   where \( H_m[k] \) is the \( m \)-th Mel filter.

6. **Discrete Cosine Transform (DCT)**  
   Apply DCT to decorrelate and obtain MFCCs:
   \[
   \text{MFCC}[n] = \sum_{m=1}^{M} E_m \cdot \cos\left[\frac{\pi n (m - 0.5)}{M}\right], \quad n = 1, \dots, L
   \]

The result is a \( T \times d \) matrix, where:
- \( T \): number of frames
- \( d \): number of cepstral coefficients (typically 12â€“13)

---

### ğŸ“ 2. DTW â€” Dynamic Time Warping

Dynamic Time Warping is an algorithm for measuring similarity between two temporal sequences that may vary in time or speed. It finds the **optimal alignment path** with minimal cumulative distance.

#### ğŸ§® Let:

- \( X = [\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_N] \in \mathbb{R}^{N \times d} \): MFCCs from the test input
- \( Y = [\mathbf{y}_1, \mathbf{y}_2, \dots, \mathbf{y}_M] \in \mathbb{R}^{M \times d} \): MFCCs from a training template

#### ğŸ“ Step 1: Local Distance Matrix

Compute Euclidean distances:
\[
D(i, j) = \| \mathbf{x}_i - \mathbf{y}_j \|_2 = \sqrt{\sum_{k=1}^{d} (x_i^{(k)} - y_j^{(k)})^2}
\]

#### ğŸ” Step 2: Dynamic Programming (Cumulative Distance Matrix)

Define a cost matrix \( C \in \mathbb{R}^{(N+1) \times (M+1)} \) initialized as:
\[
C(0, 0) = 0,\quad C(i, 0) = C(0, j) = \infty
\]

Recursively compute:
\[
C(i, j) = D(i, j) + \min \left\{
\begin{array}{l}
C(i-1, j) \\
C(i, j-1) \\
C(i-1, j-1)
\end{array}
\right.
\]

#### âœ… Step 3: Final DTW Distance

The DTW distance is the minimum cost to align the two sequences:
\[
\text{DTW}(X, Y) = C(N, M)
\]

Lower DTW values indicate better matches.

---

## ğŸ–¥ï¸ Example Output


---

## ğŸ—‚ï¸ Project Setup

### ğŸ“ Folder Structure

BanglaSpeechRecognition/
â”œâ”€â”€ audio/
â”‚ â”œâ”€â”€ ashun_1.wav, ashun_2.wav
â”‚ â”œâ”€â”€ ha_1.wav, ha_2.wav
â”‚ â”œâ”€â”€ na_1.wav, na_2.wav
â”‚ â”œâ”€â”€ biday_1.wav, biday_2.wav
â”‚ â”œâ”€â”€ bonfho_1.wav, bonfho_2.wav
â”‚ â””â”€â”€ input.wav
â”œâ”€â”€ create_templates.m
â”œâ”€â”€ main.m
â”œâ”€â”€ extract_mfcc.m
â”œâ”€â”€ preprocess_audio.m
â”œâ”€â”€ normalize_features.m
â””â”€â”€ dtw_distance.m

---

## ğŸš€ How to Use

1. ğŸ“¥ Record or add WAV files to the `audio/` folder.
2. ğŸ”§ Run `create_templates.m` to extract and store MFCCs.
3. ğŸ§ª Run `main.m` to test `input.wav` and recognize the word.

---

## ğŸ“Œ Limitations

- Works only for **isolated words**
- Sensitive to **background noise** and **speaker variation**
- Not suitable for **continuous speech recognition**

---

## ğŸ’¡ Future Improvements

- Add **voice activity detection (VAD)** for automatic speech segmentation
- Use **MFCC + HMM/SVM/CNN** for robust classification
- Train on multiple speakers for speaker-independent recognition
- Implement in real-time or deploy on embedded devices

---

## ğŸ§‘â€ğŸ’» Author

**Oshayer Siddique**  
Department of Computer Science  
Islamic University of Technology  

---

## ğŸ“œ License

MIT License â€” free to use, modify, and distribute with attribution.

